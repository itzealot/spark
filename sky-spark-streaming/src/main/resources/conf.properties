ga.app.name=ga-mass-streaming-test

ga.streaming.main.class=com.ga.projects.spark.SparkJobMain

ga.zookeeper.url=rzx168:2181,rzx169:2181,rzx177:2181/kafka

ga.brokers=rzx168:9092,rzx169:9092,rzx177:9092
ga.topic.group=testGroup
ga.topic=wl_none
ga.kafka.mode=last

# hdfs config
ga.core_site=/etc/hadoop/conf/core-site.xml
ga.hdfs_site=/etc/hadoop/conf/hdfs-site.xml
ga.yarn_site=/etc/hadoop/conf/yarn-site.xml

ga.driver-memory=1g
ga.num-executors=3
ga.executor-memory=2g
ga.executor-cores=2
ga.driver-java-options=-XX:MaxPermSize=256m -XX:+UseConcMarkSweepGC -XX:+CMSConcurrentMTEnabled -XX:ConcGCThreads=8 -XX:+CMSParallelRemarkEnabled
ga.executor-java-options=-Xmn1g -XX:+UseConcMarkSweepGC -XX:+CMSConcurrentMTEnabled -XX:ConcGCThreads=8 -XX:+CMSParallelRemarkEnabled -XX:-UseGCOverheadLimit
ga.maxRatePerPartition=100
ga.jobDuration=20
ga.groupByKeyNum=3

# spark settings
# spark memory overhead on yarn
spark.yarn.executor.memoryOverhead=1024